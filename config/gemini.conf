# Veil Armor Configuration
# Complete OWASP Top 10 LLM Vulnerabilities Implementation

[app]
name = "veil-armor"
version = "2.0.0"
host = "0.0.0.0"
port = 5000
debug = false
workers = 4

[security]
api_key_enabled = true
api_key = ""  # Set via environment variable VEIL_ARMOR_API_KEY
cors_enabled = true
cors_origins = ["http://localhost:3000", "http://localhost:5000"]
jwt_secret = ""  # Set via environment variable JWT_SECRET

# ===== LLM API Configuration (Gemini) =====
[gemini]
# Google Gemini API (new google-genai SDK)
api_key = ""  # Set via environment variable GEMINI_API_KEY
model = "gemini-2.0-flash"  # gemini-2.0-flash, gemini-2.0-pro
embedding_model = "models/embedding-001"
temperature = 0.7
max_output_tokens = 2048
top_p = 0.95
top_k = 40

# ===== LLM01: Prompt Injection Detection (Vigil) =====
[vigil]
enabled = true
config_path = "config/vigil.conf"
# Vigil uses its own scanners: VectorDB, YARA, Transformer, Similarity, Canary

[scanners]
# Enable/disable individual scanners
vectordb_enabled = true
yara_enabled = true
transformer_enabled = true
similarity_enabled = true
sentiment_enabled = false
pii_enabled = true              # LLM02
hallucination_enabled = true    # LLM09

# Scanner weights for risk scoring (must sum to 1.0)
vectordb_weight = 0.25
yara_weight = 0.25
transformer_weight = 0.25
pii_weight = 0.15
hallucination_weight = 0.10

[vectordb]
type = "chromadb"
path = "data/vectordb"
collection_name = "veil_armor_threats"
embedding_model = "sentence-transformers/all-MiniLM-L6-v2"
embedding_dimension = 384
similarity_threshold = 0.85
top_k = 5
auto_update_enabled = true
auto_update_threshold = 0.95

[transformer]
model_name = "deepset/deberta-v3-base-injection"
device = "cpu"
threshold = 0.98
max_length = 512

[yara]
rules_path = "data/yara_rules"
compiled_rules_path = "data/yara_rules/compiled_rules.yarc"
auto_compile = true
categories = [
    "instruction_bypass",
    "jailbreak",
    "data_exfiltration",
    "goal_hijacking",
    "prompt_leakage"
]

[similarity]
enabled = true
threshold = 0.15
model = "sentence-transformers/all-MiniLM-L6-v2"

[sentiment]
enabled = false
model = "cardiffnlp/twitter-roberta-base-sentiment"
suspicious_threshold = 0.85

# ===== LLM02: Sensitive Information Disclosure (Presidio) =====
[pii]
enabled = true
language = "en"
threshold = 0.5  # Detection confidence threshold

# Entity types to detect
entities = [
    "CREDIT_CARD",
    "CRYPTO",
    "EMAIL_ADDRESS",
    "IBAN_CODE",
    "IP_ADDRESS",
    "NRP",
    "PERSON",
    "PHONE_NUMBER",
    "US_SSN",
    "US_BANK_NUMBER",
    "US_DRIVER_LICENSE",
    "US_PASSPORT",
    "LOCATION",
    "DATE_TIME",
    "MEDICAL_LICENSE",
    "URL"
]

# Auto-redact PII in responses
auto_redact = true
redaction_method = "replace"  # replace, mask, redact, hash

# ===== LLM03: Supply Chain Vulnerabilities (Trivy) =====
[supply_chain]
enabled = true
trivy_path = "trivy"  # Path to Trivy binary
scan_on_startup = true
scan_interval_hours = 24
severity_threshold = "MEDIUM"  # LOW, MEDIUM, HIGH, CRITICAL
report_path = "logs/supply_chain_scan.json"

# Dependencies to scan
scan_targets = [
    "requirements.txt",
    "pyproject.toml",
    "."  # Scan entire directory
]

# ===== LLM04: Data/Model Poisoning Detection =====
[poisoning_detection]
enabled = true
anomaly_threshold = 0.95  # IsolationForest threshold
min_samples = 100  # Minimum samples before enabling
sample_window = 1000  # Rolling window of recent samples
contamination = 0.1  # Expected percentage of anomalies

# Features to monitor
monitor_features = [
    "prompt_length",
    "response_length",
    "token_count",
    "similarity_score",
    "embedding_variance"
]

# ===== LLM05: Improper Output Handling (Guardrails) =====
[output_sanitizer]
enabled = true

# HTML sanitization
allowed_html_tags = ["p", "br", "strong", "em", "ul", "ol", "li"]
allowed_attributes = {"*": ["class"]}

# Toxic content detection
toxic_threshold = 0.5
block_toxic = true

# Competitor mentions to filter
competitors = []  # Add competitor names to block

# Code injection patterns
block_code_injection = true

# Prompt leakage detection
detect_prompt_leakage = true

# ===== LLM06: Excessive Agency =====
[agency_limiter]
enabled = true

# Maximum actions per session
max_actions_per_session = 10

# Maximum API calls per request
max_api_calls_per_request = 3

# Allowed action types
allowed_actions = [
    "read",
    "search",
    "analyze"
]

# Require approval for sensitive actions
require_approval = [
    "write",
    "delete",
    "execute",
    "external_api"
]

# Action timeout
action_timeout_seconds = 30

# ===== LLM07: System Prompt Leakage (Canary Tokens) =====
[canary]
enabled = true
default_length = 16
default_header = "<-@!-- {canary} --@!->"
storage_path = "data/canary_tokens.db"

# Canary patterns
patterns = [
    "<-@!--.*?--@!->",
    "\\[CANARY:.*?\\]",
    "<<<.*?>>>",
    "##CANARY##.*?##/CANARY##"
]

# Alert on detection
alert_on_detection = true
alert_webhook = ""  # Webhook URL for alerts

# ===== LLM08: Vector/Embedding Weaknesses =====
[rag_security]
enabled = true

# Input validation for RAG queries
max_query_length = 1000
min_query_length = 3
sanitize_queries = true

# Embedding security
detect_embedding_attacks = true
embedding_distance_threshold = 0.9  # Flag suspiciously similar embeddings

# Source validation
validate_sources = true
allowed_sources = []  # Whitelist of allowed document sources
blocked_patterns = ["<script", "javascript:", "eval(", "exec("]

# Metadata filtering
filter_metadata = true
sensitive_metadata_keys = ["password", "api_key", "token", "secret"]

# ===== LLM09: Misinformation/Hallucination Detection =====
[hallucination]
enabled = true
model = "gemini-2.0-flash"  # Use Gemini for fact-checking
confidence_threshold = 0.7  # Below this = potential hallucination
consistency_checks = 3  # Number of consistency checks

# Detection modes
enable_confidence_check = true
enable_fact_check = false  # Requires context/sources
enable_consistency_check = false  # More expensive

# Citation requirements
require_citations = false
verify_citations = false

# ===== LLM10: Unbounded Consumption (Rate Limiting) =====
[rate_limit]
enabled = true
storage_uri = "memory://"  # memory:// or redis://localhost:6379/0

# Default limits (unauthenticated)
default_limit = "10/minute"
default_hourly_limit = "100/hour"
default_daily_limit = "1000/day"

# Authenticated user limits
authenticated_limit = "100/minute"
authenticated_hourly_limit = "1000/hour"
authenticated_daily_limit = "10000/day"

# Burst protection
burst_limit = "50/minute"
token_bucket_capacity = 100
token_bucket_refill_rate = 10.0  # tokens per second

# Cost-based limiting
enable_cost_limiting = true
default_budget_hourly = 10.0  # USD per hour
token_cost = 0.0001  # USD per token (example)

# DDoS protection
enable_ddos_protection = true
ddos_threshold = "1000/minute"
ddos_ban_duration_seconds = 3600

# ===== Logging =====
[logging]
level = "INFO"
format = "json"
file = "logs/veil_armor.log"
max_file_size_mb = 100
backup_count = 5
log_detections = true
log_path = "logs/detections.jsonl"

# Security event logging
log_security_events = true
security_log_path = "logs/security_events.jsonl"

# ===== Monitoring =====
[monitoring]
prometheus_enabled = true
prometheus_port = 9090
metrics_path = "/metrics"

# Metrics to track
track_latency = true
track_threats = true
track_false_positives = false

# Alerting
enable_alerts = false
alert_webhook = ""
alert_on_critical = true

# ===== Performance =====
[performance]
batch_size = 32
max_concurrent_requests = 100
timeout_seconds = 30
cache_enabled = true
cache_ttl_seconds = 3600

# Connection pooling
connection_pool_size = 10
connection_pool_timeout = 30

# ===== Response Configuration =====
[response]
include_explanations = true
include_scanner_details = true
sanitize_output = true
default_safe_response = "I cannot process this request due to security concerns."

# Response headers
add_security_headers = true
security_headers = [
    "X-Content-Type-Options: nosniff",
    "X-Frame-Options: DENY",
    "X-XSS-Protection: 1; mode=block",
    "Strict-Transport-Security: max-age=31536000"
]

# ===== Datasets =====
[datasets]
instruction_bypass_dataset = "deadbits/vigil-instruction-bypass"
jailbreak_dataset = "deadbits/vigil-jailbreak"
custom_datasets = []
